{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Classifiers\n",
    "*Paulo G. Martinez* Sat. Apr. 4, 2020\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier-kitchen-sink\n",
    "Attempt efficient classifier comparison and promotion\n",
    "\n",
    "## This is an experiment in \"elegant brute force.\"\n",
    "- Given a \"large\" but \"tidy\" data set with a \"wide\" set of potentially sparse and or redundant numeric, categorical, and datetime features and multiple \"imbalaced\" targets (not a multi class column, but two or more binary class target columns)\n",
    "  - Attempt to find an efficient way of comparing the success of various classification models \n",
    "  -   each with various model configurations\n",
    "\n",
    "P1. One of the premises of this experiment is that it would take \"too much\" time to assess the viability, let alone solve the problem using a \"traditional\" domain-knowledge based approach.\n",
    "\n",
    "P2. Another premise is that compute and memory resources are so limited that a brute force iteration through models would also take \"too long.\"\n",
    "\n",
    "## Workflow 1.0\n",
    "\"Failing Fast.\" We begin with the most challenging but easiest to compute configurations in hopes of fiding success before having to \"bloat\" all the way up to full brute-force iteration\n",
    "\n",
    "For each binary-classification target\n",
    "- find \"natural\" class_weights\n",
    "- for sample_size in [small, medium, ... large, full]:\n",
    "  - for weight_balance in [natural_weights, slight_upsample, ..., aggressive_upsample]:\n",
    "    - for model in [rf, cnb, boost, etc]:\n",
    "      - pre-process features\n",
    "        - impute nulls\n",
    "        - perhaps scale\n",
    "        - fit, train, test model\n",
    "        - score model\n",
    "        - score feature importance\n",
    "        - while model scores unsatisfactorily and features refinement is possible:\n",
    "          - refine feature selection\n",
    "          - refit, retrain, retest, rescore\n",
    "          - (if model fails to score satisfactorily move on to next model)\n",
    "        - **if model scores satisfactorily on sample**\n",
    "          - save model, its score and config to \"training_sample_weight_success\"\n",
    "             - out_of_sample test and score model on increasingly larger samples\n",
    "            - **if model scores satisfactorily when \"generalized\" to data out of its training sample:**\n",
    "              - save model, its score and config to \"training_sample_weight_generalsample_success\"\n",
    "              - (if model failed to generalize well move on to next model)\n",
    "      - (when all models have been evaluated on this class weight, upsample and repeat.)\n",
    "    - (when all weight resampling's have been attempted increase the sample size and repeat.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reveal data structures for clarity during dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the data we'll be developing on, it's a slightly modified version of the titanic data set\n",
    "if 'pd' not in vars():\n",
    "    import pandas as pd\n",
    "pd.read_csv('data/semi_processed_all.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pd' not in vars():\n",
    "    import pandas as pd\n",
    "pd.read_csv('data/semi_processed_all.csv').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Functions and Script\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declare Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare some global variables\n",
    "using_TSNE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prep environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open source software packages\n",
    "# numerical manipulation and analysis\n",
    "import numpy as np\n",
    "# data frame manipulation and analysis\n",
    "import pandas as pd\n",
    "# sci-kit learn modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "#from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# import builtins\n",
    "from datetime import datetime\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "if using_TSNE:\n",
    "    import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting targets' natural class-weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_class_count_weight_and_recordkeys(targets = [], data = None, verbose = True):\n",
    "    '''\n",
    "    Get the class weights of a set of target columns in a dataframe \n",
    "    (with unique indices)or its equivalent index-oriented dictionary. \n",
    "    Print the information and return it as a dictionary of classes and \n",
    "    weights in the following format:\n",
    "    {\n",
    "        'total_count': tc,\n",
    "        target_col : {\n",
    "            class_a : {\n",
    "                'natural_count':nc,\n",
    "                'natural_weight': nw,\n",
    "                'records': {i0, i1, ..., 1nc}\n",
    "            },\n",
    "            class_b : {\n",
    "                'natural_count':nc,\n",
    "                'natural_weight': nw,\n",
    "                'records': {i0, i1, ..., 1nc}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Expects datetime and pandas to be available.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    targets : list of target-column names in a dataframelike object.\n",
    "        Default []\n",
    "    \n",
    "    data: a pandas.DataFrame or its .to_dict(orient = 'index') equivalent. \n",
    "        Default None\n",
    "    \n",
    "    verbose: boolean. Whether or not the function prints out feedback.\n",
    "        Default True\n",
    "    '''\n",
    "    if verbose:\n",
    "        feedback = 'Getting class weights'\n",
    "        print(feedback+'\\n'+'-'*len(feedback))\n",
    "        \n",
    "    # validate non falsy inputs\n",
    "    for var in {'targets': targets, 'data': data}:\n",
    "        # if empty or null\n",
    "        if not var:\n",
    "            raise TypeError(f'''Expected non empty input for {var} but received \"falsy\" type {type(var)}''')\n",
    "    \n",
    "    # if received dataframe cast it to dict and continue\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        # ignore the columns we won't use\n",
    "        data = data[targets].to_dict(orient = 'index')\n",
    "    \n",
    "    # workflow for data dictionary\n",
    "    if isinstance(data, dict):\n",
    "        # initialize storage dict\n",
    "        target_class_weights = {}\n",
    "        \n",
    "        # get length of data\n",
    "        data_length = len(data)\n",
    "        if verbose:\n",
    "            print(datetime.now(), \"Available Data Records:\", f\"{data_length:.2E} = {data_length:,}\\n\")\n",
    "        target_class_weights['total_count'] = data_length\n",
    "        \n",
    "        for target_col in targets:\n",
    "            if verbose:\n",
    "                print(datetime.now(), 'weighing classes in target:', target_col)\n",
    "            # initialize a dict for each target column \n",
    "            target_class_weights[target_col] = {}\n",
    "            \n",
    "            # iterate once through the records to get each classes keys\n",
    "            for record in data:\n",
    "                # get the class label at that record\n",
    "                class_label = data[record][target_col]\n",
    "                \n",
    "                # if first time seeing this class, initialize its own dict\n",
    "                if class_label not in target_class_weights[target_col]:\n",
    "                    # initialize its set of records (to avoid the need for iteration searches downstream)\n",
    "                    target_class_weights[target_col][class_label] = {'records':set()}\n",
    "                \n",
    "                # update this class' set of records\n",
    "                target_class_weights[target_col][class_label]['records'].add(record)\n",
    "            \n",
    "            # now that we have each class's set of records, save its count and weight for convenience\n",
    "            for class_label in target_class_weights[target_col]:\n",
    "                target_class_weights[target_col][class_label]['natural_count'] = len(target_class_weights[target_col][class_label]['records'])\n",
    "                target_class_weights[target_col][class_label]['natural_weight'] = target_class_weights[target_col][class_label]['natural_count']/target_class_weights['total_count']\n",
    "                if verbose:\n",
    "                    print(f\"class:{class_label}\")\n",
    "                    for attribute in ['natural_count', 'natural_weight']:\n",
    "                        print(f\"- {attribute}: {target_class_weights[target_col][class_label][attribute]}\")\n",
    "            if verbose:\n",
    "                print('')\n",
    "    # if neither data frame nor dict\n",
    "    else:\n",
    "        raise TypeError(f'Expected data to be type dict or pd.DataFrame but instead got type: {type(data)}')\n",
    "    \n",
    "    return target_class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting data sample of given weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weighted_data_samples(\n",
    "    class_counts_weights_keys = {}, sample_pct = .10, sample_weights = {}, \n",
    "    verbose = False, return_dict = False\n",
    "):\n",
    "    '''\n",
    "    Takes a dictionary denoting a set of classes, and the data keys that correspond to them in a data set.\n",
    "    Returns a list of random samples to meet the size and weighting specifications.\n",
    "    - Classes will be upsampled or downsampled to meet the requested parameters.\n",
    "    - When upsampling, all unique records will be added once, then additional records will be added at random\n",
    "        with replacement\n",
    "        \n",
    "    Requires numpy.random.choice\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    class_counts_weight_keys: dictionary with the following features where the 'records' contain the \n",
    "        keys or indices of records in a data dictionary or dataframe.\n",
    "        Default {} empty dict (will fail).\n",
    "        {\n",
    "            class_a : {\n",
    "                'natural_count':nc,\n",
    "                'natural_weight': nw,\n",
    "                'records': {i0, i1, ..., 1nc}\n",
    "            },\n",
    "            class_b : {\n",
    "                'natural_count':nc,\n",
    "                'natural_weight': nw,\n",
    "                'records': {i0, i1, ..., 1nc}\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    sample_pct: float between (0,1] denoting the percetage of the original data to be sampled\n",
    "        Default .10\n",
    "        \n",
    "    sample_weights: dictionary of classes and their desired weights in the data sample.\n",
    "        Ex: {class_a:.50, class_b:.50}\n",
    "    \n",
    "    verbose: boolean, whether to print feedback or not\n",
    "        Default False\n",
    "        \n",
    "    return_dict: boolean, whether to return a second object. Optionally Also Returns a similar \n",
    "        dictionary of the same classes denoting their sampled count, sampled weight and a list\n",
    "        of their sampled keys (returns a list because upsampling migh require duplicate keys). \n",
    "        Default False\n",
    "        \n",
    "    '''\n",
    "    # validate inputs\n",
    "    for variable in [class_counts_weights_keys, sample_weights]:\n",
    "        if not isinstance(variable, dict):\n",
    "            raise TypeError(f\"Expected type dict but received type{type(variable)}.\")\n",
    "    \n",
    "    # initialize list of data keys to return\n",
    "    use_records = []\n",
    "    # initialize dictionary to return\n",
    "    sample_class_counts_weights_keys = {\n",
    "        class_label:{\n",
    "            'sample_count': None,\n",
    "            'sample_weight':None,\n",
    "            'sample_records':[]\n",
    "        } \n",
    "        for class_label in class_counts_weights_keys\n",
    "    }\n",
    "    \n",
    "    # get total count of available data\n",
    "    total_count = 0\n",
    "    for class_label in class_counts_weights_keys:\n",
    "        total_count += class_counts_weights_keys[class_label]['natural_count']\n",
    "        if class_label not in sample_weights:\n",
    "            raise NameError(f\"class: {class_label} not in sample_weights {sample_weights.keys()} If you don't want it in the sample assign its weight to 0\")\n",
    "    \n",
    "    # determine the requested size of the sample\n",
    "    sample_size = int(total_count*sample_pct)\n",
    "    if verbose:\n",
    "        print('Requested sample size:', sample_size)\n",
    "    \n",
    "    # for each class\n",
    "    for class_label in class_counts_weights_keys:\n",
    "        \n",
    "        # determine and save the number of class samples requested\n",
    "        requested_class_count = int(sample_size*sample_weights[class_label])\n",
    "        if verbose:\n",
    "            print('requested_class_count:', class_label, requested_class_count)\n",
    "        \n",
    "        # determine if upsampling will be required\n",
    "        if requested_class_count > class_counts_weights_keys[class_label]['natural_count']:\n",
    "            if verbose:\n",
    "                print(f\"class: {class_label} is too small by {requested_class_count - class_counts_weights_keys[class_label]['natural_count']}\\n Upsampling\")\n",
    "            # add all the unique records available\n",
    "            use_records += list(class_counts_weights_keys[class_label]['records'])\n",
    "            # add all the unique records to the class' sample records\n",
    "            sample_class_counts_weights_keys[class_label]['sample_records'] += list(class_counts_weights_keys[class_label]['records'])\n",
    "            replacement = True\n",
    "            # define how many replacement samples still need to be added\n",
    "            outstanding = requested_class_count - class_counts_weights_keys[class_label]['natural_count']\n",
    "        \n",
    "        # determine if downsampling will be required\n",
    "        if requested_class_count <= class_counts_weights_keys[class_label]['natural_count']:\n",
    "            if verbose:\n",
    "                print(f\"class: {class_label} is too large by {class_counts_weights_keys[class_label]['natural_count'] - requested_class_count}\\n Downsampling\")\n",
    "            replacement = False\n",
    "            outstanding = requested_class_count\n",
    "        \n",
    "        # get outstanding samples to be added\n",
    "        class_samples = np.random.choice(list(class_counts_weights_keys[class_label]['records']), size = outstanding, replace = replacement)\n",
    "        class_samples = list(class_samples)\n",
    "        # add the class samples to the list of records to be used.\n",
    "        use_records += class_samples\n",
    "        # add and save the class samples to be used\n",
    "        sample_class_counts_weights_keys[class_label]['sample_records'] += class_samples\n",
    "        \n",
    "        # spot check to make sure it worked as expected\n",
    "        # get the new count of class samples in use_records\n",
    "        returned_class_count = sum([record in class_counts_weights_keys[class_label]['records'] for record in use_records])\n",
    "        returned_class_weight = returned_class_count/sample_size\n",
    "        assert returned_class_count == requested_class_count\n",
    "        # save class sample counts and weights for output\n",
    "        sample_class_counts_weights_keys[class_label]['sample_count'] = returned_class_count\n",
    "        sample_class_counts_weights_keys[class_label]['sample_weight'] = returned_class_weight\n",
    "        if verbose:\n",
    "            print(f\"class:{class_label}\\n resampled to weight:{np.round(returned_class_weight, 2)}, count:{returned_class_count}\\n\")\n",
    "    \n",
    "    if verbose:\n",
    "            print(datetime.now(), 'Done resampling')\n",
    "            \n",
    "    if not return_dict:\n",
    "        return use_records\n",
    "    else:\n",
    "        return use_records, sample_class_counts_weights_keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare \"Script\" Variables (i.e. input parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load data**\n",
    "\n",
    "Use titanic data set for its mix of numeric and categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data as a dictionary, because they are more efficient when large and of konwn structure than dataframes are\n",
    "data = pd.read_csv('data/semi_processed_all.csv').to_dict(orient = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**declare target columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['EMBARKED_Q', 'EMBARKED_S', 'EMBARKED_C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "\n",
    "# declare sample sizes as percentages of total data size\n",
    "sample_size_percents = [.10, .20, .40, .80, 1.00]\n",
    "# validate sample pcts\n",
    "for pct in sample_size_percents:\n",
    "    if (pct <= 0) or (pct > 1):\n",
    "        raise ValueError(f\"Expected percentage between (0, 1] but received {pct}\")\n",
    "\n",
    "# declare weight configurations to use\n",
    "use_natural_weights = True\n",
    "use_balanced_weights = True\n",
    "class_weight_configs = [{True:.20, False:.80},{True:.30, False:.70}]\n",
    "# Validation for each class_weight configuration\n",
    "for weighting in class_weight_configs:\n",
    "    # spot check that they add up to 1 (for 100%)\n",
    "    if not np.round(pd.Series(weighting).sum(), 2) == 1:\n",
    "        raise ValueError(f'Invalid or incomplete class weight values. Expected sum to about 1 but got {pd.Series(weighting)}')\n",
    "\n",
    "# declare classifiers to use\n",
    "classifiers = {\n",
    "    \"Complement_Naive_Bayes\" : ComplementNB(),\n",
    "    \"Random_Forest_Classifier\": RandomForestClassifier(),\n",
    "    \"Nearest_Neighbors\" : KNeighborsClassifier(),\n",
    "    \"Add_a_Boost\": AdaBoostClassifier(),\n",
    "    \"Neural_Network\" : MLPClassifier()\n",
    "}\n",
    "# declare which models need their features scaled\n",
    "needs_scaling = {\"Nearest_Neighbors\", \"Neural_Network\"}\n",
    "\n",
    "        \n",
    "# if testing/debuging on a single target\n",
    "one_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-05 18:13:33.657040 WORKING ON TARGET COLUMN: EMBARKED_Q\n",
      "===================================================\n",
      "Getting class weights\n",
      "---------------------\n",
      "2020-04-05 18:13:33.657320 Available Data Records: 1.31E+03 = 1,309\n",
      "\n",
      "2020-04-05 18:13:33.657395 weighing classes in target: EMBARKED_Q\n",
      "class:False\n",
      "- natural_count: 1186\n",
      "- natural_weight: 0.906035141329259\n",
      "class:True\n",
      "- natural_count: 123\n",
      "- natural_weight: 0.09396485867074103\n",
      "\n",
      "get 0.1 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "------------------------------------\n",
      "Requested sample size: 130\n",
      "requested_class_count: False 117\n",
      "class: False is too large by 1069\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.9, count:117\n",
      "\n",
      "requested_class_count: True 12\n",
      "class: True is too large by 111\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.09, count:12\n",
      "\n",
      "2020-04-05 18:13:33.659886 Done resampling\n",
      "\n",
      "get 0.1 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "------------------------------------\n",
      "Requested sample size: 130\n",
      "requested_class_count: False 117\n",
      "class: False is too large by 1069\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.9, count:117\n",
      "\n",
      "requested_class_count: True 12\n",
      "class: True is too large by 111\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.09, count:12\n",
      "\n",
      "2020-04-05 18:13:33.661440 Done resampling\n",
      "\n",
      "get 0.1 percent sample with weights: {True: 0.2, False: 0.8}\n",
      "------------------------------------\n",
      "Requested sample size: 130\n",
      "requested_class_count: False 104\n",
      "class: False is too large by 1082\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.8, count:104\n",
      "\n",
      "requested_class_count: True 26\n",
      "class: True is too large by 97\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.2, count:26\n",
      "\n",
      "2020-04-05 18:13:33.662922 Done resampling\n",
      "\n",
      "get 0.1 percent sample with weights: {True: 0.3, False: 0.7}\n",
      "------------------------------------\n",
      "Requested sample size: 130\n",
      "requested_class_count: False 91\n",
      "class: False is too large by 1095\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.7, count:91\n",
      "\n",
      "requested_class_count: True 39\n",
      "class: True is too large by 84\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.3, count:39\n",
      "\n",
      "2020-04-05 18:13:33.664465 Done resampling\n",
      "\n",
      "get 0.1 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "------------------------------------\n",
      "Requested sample size: 130\n",
      "requested_class_count: False 65\n",
      "class: False is too large by 1121\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.5, count:65\n",
      "\n",
      "requested_class_count: True 65\n",
      "class: True is too large by 58\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.5, count:65\n",
      "\n",
      "2020-04-05 18:13:33.667147 Done resampling\n",
      "\n",
      "get 0.1 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "------------------------------------\n",
      "Requested sample size: 130\n",
      "requested_class_count: False 65\n",
      "class: False is too large by 1121\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.5, count:65\n",
      "\n",
      "requested_class_count: True 65\n",
      "class: True is too large by 58\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.5, count:65\n",
      "\n",
      "2020-04-05 18:13:33.668318 Done resampling\n",
      "\n",
      "get 0.2 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "------------------------------------\n",
      "Requested sample size: 261\n",
      "requested_class_count: False 236\n",
      "class: False is too large by 950\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.9, count:236\n",
      "\n",
      "requested_class_count: True 24\n",
      "class: True is too large by 99\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.09, count:24\n",
      "\n",
      "2020-04-05 18:13:33.670274 Done resampling\n",
      "\n",
      "get 0.2 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "------------------------------------\n",
      "Requested sample size: 261\n",
      "requested_class_count: False 236\n",
      "class: False is too large by 950\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.9, count:236\n",
      "\n",
      "requested_class_count: True 24\n",
      "class: True is too large by 99\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.09, count:24\n",
      "\n",
      "2020-04-05 18:13:33.672288 Done resampling\n",
      "\n",
      "get 0.2 percent sample with weights: {True: 0.2, False: 0.8}\n",
      "------------------------------------\n",
      "Requested sample size: 261\n",
      "requested_class_count: False 208\n",
      "class: False is too large by 978\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.8, count:208\n",
      "\n",
      "requested_class_count: True 52\n",
      "class: True is too large by 71\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.2, count:52\n",
      "\n",
      "2020-04-05 18:13:33.674437 Done resampling\n",
      "\n",
      "get 0.2 percent sample with weights: {True: 0.3, False: 0.7}\n",
      "------------------------------------\n",
      "Requested sample size: 261\n",
      "requested_class_count: False 182\n",
      "class: False is too large by 1004\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.7, count:182\n",
      "\n",
      "requested_class_count: True 78\n",
      "class: True is too large by 45\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.3, count:78\n",
      "\n",
      "2020-04-05 18:13:33.675771 Done resampling\n",
      "\n",
      "get 0.2 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "------------------------------------\n",
      "Requested sample size: 261\n",
      "requested_class_count: False 130\n",
      "class: False is too large by 1056\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.5, count:130\n",
      "\n",
      "requested_class_count: True 130\n",
      "class: True is too small by 7\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.5, count:130\n",
      "\n",
      "2020-04-05 18:13:33.676873 Done resampling\n",
      "\n",
      "get 0.2 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "------------------------------------\n",
      "Requested sample size: 261\n",
      "requested_class_count: False 130\n",
      "class: False is too large by 1056\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.5, count:130\n",
      "\n",
      "requested_class_count: True 130\n",
      "class: True is too small by 7\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.5, count:130\n",
      "\n",
      "2020-04-05 18:13:33.678047 Done resampling\n",
      "\n",
      "get 0.4 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "------------------------------------\n",
      "Requested sample size: 523\n",
      "requested_class_count: False 473\n",
      "class: False is too large by 713\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.9, count:473\n",
      "\n",
      "requested_class_count: True 49\n",
      "class: True is too large by 74\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.09, count:49\n",
      "\n",
      "2020-04-05 18:13:33.679556 Done resampling\n",
      "\n",
      "get 0.4 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "------------------------------------\n",
      "Requested sample size: 523\n",
      "requested_class_count: False 473\n",
      "class: False is too large by 713\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.9, count:473\n",
      "\n",
      "requested_class_count: True 49\n",
      "class: True is too large by 74\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.09, count:49\n",
      "\n",
      "2020-04-05 18:13:33.681261 Done resampling\n",
      "\n",
      "get 0.4 percent sample with weights: {True: 0.2, False: 0.8}\n",
      "------------------------------------\n",
      "Requested sample size: 523\n",
      "requested_class_count: False 418\n",
      "class: False is too large by 768\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.8, count:418\n",
      "\n",
      "requested_class_count: True 104\n",
      "class: True is too large by 19\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.2, count:104\n",
      "\n",
      "2020-04-05 18:13:33.683234 Done resampling\n",
      "\n",
      "get 0.4 percent sample with weights: {True: 0.3, False: 0.7}\n",
      "------------------------------------\n",
      "Requested sample size: 523\n",
      "requested_class_count: False 366\n",
      "class: False is too large by 820\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.7, count:366\n",
      "\n",
      "requested_class_count: True 156\n",
      "class: True is too small by 33\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.3, count:156\n",
      "\n",
      "2020-04-05 18:13:33.685003 Done resampling\n",
      "\n",
      "get 0.4 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "------------------------------------\n",
      "Requested sample size: 523\n",
      "requested_class_count: False 261\n",
      "class: False is too large by 925\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.5, count:261\n",
      "\n",
      "requested_class_count: True 261\n",
      "class: True is too small by 138\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.5, count:261\n",
      "\n",
      "2020-04-05 18:13:33.686523 Done resampling\n",
      "\n",
      "get 0.4 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "------------------------------------\n",
      "Requested sample size: 523\n",
      "requested_class_count: False 261\n",
      "class: False is too large by 925\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.5, count:261\n",
      "\n",
      "requested_class_count: True 261\n",
      "class: True is too small by 138\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.5, count:261\n",
      "\n",
      "2020-04-05 18:13:33.688023 Done resampling\n",
      "\n",
      "get 0.8 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "------------------------------------\n",
      "Requested sample size: 1047\n",
      "requested_class_count: False 948\n",
      "class: False is too large by 238\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.91, count:948\n",
      "\n",
      "requested_class_count: True 98\n",
      "class: True is too large by 25\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.09, count:98\n",
      "\n",
      "2020-04-05 18:13:33.690358 Done resampling\n",
      "\n",
      "get 0.8 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "------------------------------------\n",
      "Requested sample size: 1047\n",
      "requested_class_count: False 948\n",
      "class: False is too large by 238\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.91, count:948\n",
      "\n",
      "requested_class_count: True 98\n",
      "class: True is too large by 25\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.09, count:98\n",
      "\n",
      "2020-04-05 18:13:33.692666 Done resampling\n",
      "\n",
      "get 0.8 percent sample with weights: {True: 0.2, False: 0.8}\n",
      "------------------------------------\n",
      "Requested sample size: 1047\n",
      "requested_class_count: False 837\n",
      "class: False is too large by 349\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.8, count:837\n",
      "\n",
      "requested_class_count: True 209\n",
      "class: True is too small by 86\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.2, count:209\n",
      "\n",
      "2020-04-05 18:13:33.699234 Done resampling\n",
      "\n",
      "get 0.8 percent sample with weights: {True: 0.3, False: 0.7}\n",
      "------------------------------------\n",
      "Requested sample size: 1047\n",
      "requested_class_count: False 732\n",
      "class: False is too large by 454\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.7, count:732\n",
      "\n",
      "requested_class_count: True 314\n",
      "class: True is too small by 191\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.3, count:314\n",
      "\n",
      "2020-04-05 18:13:33.701162 Done resampling\n",
      "\n",
      "get 0.8 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "------------------------------------\n",
      "Requested sample size: 1047\n",
      "requested_class_count: False 523\n",
      "class: False is too large by 663\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.5, count:523\n",
      "\n",
      "requested_class_count: True 523\n",
      "class: True is too small by 400\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.5, count:523\n",
      "\n",
      "2020-04-05 18:13:33.706682 Done resampling\n",
      "\n",
      "get 0.8 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "------------------------------------\n",
      "Requested sample size: 1047\n",
      "requested_class_count: False 523\n",
      "class: False is too large by 663\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.5, count:523\n",
      "\n",
      "requested_class_count: True 523\n",
      "class: True is too small by 400\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.5, count:523\n",
      "\n",
      "2020-04-05 18:13:33.709472 Done resampling\n",
      "\n",
      "get 1.0 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "------------------------------------\n",
      "Requested sample size: 1309\n",
      "requested_class_count: False 1186\n",
      "class: False is too large by 0\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.91, count:1186\n",
      "\n",
      "requested_class_count: True 123\n",
      "class: True is too large by 0\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.09, count:123\n",
      "\n",
      "2020-04-05 18:13:33.711600 Done resampling\n",
      "\n",
      "get 1.0 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "------------------------------------\n",
      "Requested sample size: 1309\n",
      "requested_class_count: False 1186\n",
      "class: False is too large by 0\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.91, count:1186\n",
      "\n",
      "requested_class_count: True 123\n",
      "class: True is too large by 0\n",
      " Downsampling\n",
      "class:True\n",
      " resampled to weight:0.09, count:123\n",
      "\n",
      "2020-04-05 18:13:33.713630 Done resampling\n",
      "\n",
      "get 1.0 percent sample with weights: {True: 0.2, False: 0.8}\n",
      "------------------------------------\n",
      "Requested sample size: 1309\n",
      "requested_class_count: False 1047\n",
      "class: False is too large by 139\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.8, count:1047\n",
      "\n",
      "requested_class_count: True 261\n",
      "class: True is too small by 138\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.2, count:261\n",
      "\n",
      "2020-04-05 18:13:33.716065 Done resampling\n",
      "\n",
      "get 1.0 percent sample with weights: {True: 0.3, False: 0.7}\n",
      "------------------------------------\n",
      "Requested sample size: 1309\n",
      "requested_class_count: False 916\n",
      "class: False is too large by 270\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.7, count:916\n",
      "\n",
      "requested_class_count: True 392\n",
      "class: True is too small by 269\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.3, count:392\n",
      "\n",
      "2020-04-05 18:13:33.722145 Done resampling\n",
      "\n",
      "get 1.0 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "------------------------------------\n",
      "Requested sample size: 1309\n",
      "requested_class_count: False 654\n",
      "class: False is too large by 532\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.5, count:654\n",
      "\n",
      "requested_class_count: True 654\n",
      "class: True is too small by 531\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.5, count:654\n",
      "\n",
      "2020-04-05 18:13:33.725164 Done resampling\n",
      "\n",
      "get 1.0 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "------------------------------------\n",
      "Requested sample size: 1309\n",
      "requested_class_count: False 654\n",
      "class: False is too large by 532\n",
      " Downsampling\n",
      "class:False\n",
      " resampled to weight:0.5, count:654\n",
      "\n",
      "requested_class_count: True 654\n",
      "class: True is too small by 531\n",
      " Upsampling\n",
      "class:True\n",
      " resampled to weight:0.5, count:654\n",
      "\n",
      "2020-04-05 18:13:33.727095 Done resampling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each target column in a single data frame\n",
    "for target in target_columns:\n",
    "    if verbose:\n",
    "        print(datetime.now(), 'WORKING ON TARGET COLUMN:', target)\n",
    "        print('===================================================')\n",
    "    \n",
    "    # get target classes, counts, weights, and recordkeys\n",
    "    class_counts_weights_keys = get_target_class_count_weight_and_recordkeys(targets=[target], data = data)[target]\n",
    "    \n",
    "    if use_natural_weights:\n",
    "        # make this the first item in the list\n",
    "        class_weight_configs = [{\n",
    "            class_label:class_counts_weights_keys[class_label]['natural_weight'] \n",
    "            for class_label in class_counts_weights_keys\n",
    "        }] + class_weight_configs\n",
    "    # get balanced class weights\n",
    "    if use_balanced_weights:\n",
    "        # make this the last item in the list\n",
    "        class_weight_configs += [{\n",
    "            clss:np.round(1/len(class_weight_configs[0]),2) for clss in class_weight_configs[0]\n",
    "        }]\n",
    "    \n",
    "    # GET WEIGHTED DATA SAMPLE\n",
    "    for sample_pct in sample_size_percents:\n",
    "        for sample_weights in class_weight_configs:\n",
    "            if verbose:\n",
    "                print('getting', sample_pct, 'percent sample with weights:', sample_weights)\n",
    "                print('------------------------------------')\n",
    "            # save (list of record keys, and dict of class sample counts and weights and corresponding record keys)\n",
    "            use_samples, sample_class_counts_weights_keys = get_class_weighted_data_samples(\n",
    "                class_counts_weights_keys = class_counts_weights_keys, \n",
    "                sample_pct = sample_pct, \n",
    "                sample_weights = sample_weights,\n",
    "                verbose = True,\n",
    "                return_dict=True\n",
    "            )\n",
    "            print('')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # FOR EACH CLASSIFIER\n",
    "        #for model in classifiers:\n",
    "            \n",
    "\n",
    "    # if testing/debugging on a single target\n",
    "    if one_run:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
