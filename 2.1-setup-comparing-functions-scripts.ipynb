{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Classifiers\n",
    "*Paulo G. Martinez* Sat. Apr. 4, 2020\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier-kitchen-sink\n",
    "Attempt efficient classifier comparison and promotion\n",
    "\n",
    "## This is an experiment in \"elegant brute force.\"\n",
    "- Given a \"large\" but \"tidy\" data set with a \"wide\" set of potentially sparse and or redundant numeric, categorical, and datetime features and multiple \"imbalaced\" targets (not a multi class column, but two or more binary class target columns)\n",
    "  - Attempt to find an efficient way of comparing the success of various classification models \n",
    "  -   each with various model configurations\n",
    "\n",
    "P1. One of the premises of this experiment is that it would take \"too much\" time to assess the viability, let alone solve the problem using a \"traditional\" domain-knowledge based approach.\n",
    "P2. Another premise is that compute and memory resources are so limited that a brute force iteration through models would also take \"too long.\"\n",
    "\n",
    "## Workflow 1.0\n",
    "\"Failing Fast.\" We begin with the most difficult but easiest to compute configurations in hopes of fiding success before having to \"bloat\" all the way up to full brute-force iteration\n",
    "\n",
    "For each binary-classification target\n",
    "- find \"natural\" class_weights\n",
    "- for sample_size in [small, medium, ... large, full]:\n",
    "  - for weight_balance in [natural_weights, slight_upsample, ..., aggressive_upsample]:\n",
    "    - for model in [rf, cnb, boost, etc]:\n",
    "      - pre-process features\n",
    "        - impute nulls\n",
    "        - perhaps scale\n",
    "        - fit, train, test model\n",
    "        - score model\n",
    "        - score feature importance\n",
    "        - while model scores unsatisfactorily and features refinement is possible:\n",
    "          - refine feature selection\n",
    "          - refit, retrain, retest, rescore\n",
    "          - (if model fails to score satisfactorily move on to next model)\n",
    "        - **if model scores satisfactorily on sample**\n",
    "          - save model, its score and config to \"training_sample_weight_success\"\n",
    "          - while unsampled training data is available:\n",
    "            - out_of_sample test and score model on increasingly larger samples\n",
    "            - **if model scores satisfactorily when \"generalized\" to data out of its training sample:**\n",
    "              - save model, its score and config to \"training_sample_weight_generalsample_success\"\n",
    "              - (if model failed to generalize well move on to next model)\n",
    "      - (when all models have been evaluated on this class weight, upsample and repeat.)\n",
    "    - (when all weight resampling's have been attempted increase the samle size and repeat.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reveal data structures for clarity during dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>EMBARKED</th>\n",
       "      <th>EMBARKED_S</th>\n",
       "      <th>EMBARKED_C</th>\n",
       "      <th>EMBARKED_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>cumings</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pc</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>stono</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass       Name     Sex   Age  SibSp  Parch Ticket     Fare  \\\n",
       "0       0.0       3     braund    male  22.0      1      0      a   7.2500   \n",
       "1       1.0       1    cumings  female  38.0      1      0     pc  71.2833   \n",
       "2       1.0       3  heikkinen  female  26.0      0      0  stono   7.9250   \n",
       "3       1.0       1   futrelle  female  35.0      1      0    NaN  53.1000   \n",
       "4       0.0       3      allen    male  35.0      0      0    NaN   8.0500   \n",
       "\n",
       "  Cabin EMBARKED  EMBARKED_S  EMBARKED_C  EMBARKED_Q  \n",
       "0   NaN        S        True       False       False  \n",
       "1   C85        C       False        True       False  \n",
       "2   NaN        S        True       False       False  \n",
       "3  C123        S        True       False       False  \n",
       "4   NaN        S        True       False       False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the data we'll be developing on, it's a slightly modified version of the titanic data set\n",
    "if 'pd' not in vars():\n",
    "    import pandas as pd\n",
    "pd.read_csv('data/semi_processed_all.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Survived    891 non-null    float64\n",
      " 1   Pclass      1309 non-null   int64  \n",
      " 2   Name        1309 non-null   object \n",
      " 3   Sex         1309 non-null   object \n",
      " 4   Age         1046 non-null   float64\n",
      " 5   SibSp       1309 non-null   int64  \n",
      " 6   Parch       1309 non-null   int64  \n",
      " 7   Ticket      352 non-null    object \n",
      " 8   Fare        1308 non-null   float64\n",
      " 9   Cabin       295 non-null    object \n",
      " 10  EMBARKED    1307 non-null   object \n",
      " 11  EMBARKED_S  1309 non-null   bool   \n",
      " 12  EMBARKED_C  1309 non-null   bool   \n",
      " 13  EMBARKED_Q  1309 non-null   bool   \n",
      "dtypes: bool(3), float64(3), int64(3), object(5)\n",
      "memory usage: 116.5+ KB\n"
     ]
    }
   ],
   "source": [
    "if 'pd' not in vars():\n",
    "    import pandas as pd\n",
    "pd.read_csv('data/semi_processed_all.csv').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Functions and Script\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declare Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare some global variables\n",
    "using_TSNE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prep environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open source software packages\n",
    "# numerical manipulation and analysis\n",
    "import numpy as np\n",
    "# data frame manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# import builtins\n",
    "from datetime import datetime\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "if using_TSNE:\n",
    "    import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting targets' natural class-weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_class_count_weight_and_recordkeys(targets = [], data = None, verbose = True):\n",
    "    '''\n",
    "    Get the class weights of a set of target columns in a dataframe \n",
    "    (with unique indices)or its equivalent index-oriented dictionary. \n",
    "    Print the information and return it as a dictionary of classes and \n",
    "    weights in the following format:\n",
    "    {\n",
    "        'total_count': tc,\n",
    "        target_col : {\n",
    "            class_a : {\n",
    "                'natural_cout':nc,\n",
    "                'natural_weight': nw,\n",
    "                'records': {i, i+1, ..., i+nc}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Expects datetime and pandas to be available.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    targets : list of target-column names in a dataframelike object.\n",
    "        Default []\n",
    "    \n",
    "    data: a pandas.DataFrame or its .to_dict(orient = 'index') equivalent. \n",
    "        Default None\n",
    "    \n",
    "    verbose: boolean. Whether or not the function prints out feedback.\n",
    "        Default True\n",
    "    '''\n",
    "    if verbose:\n",
    "        feedback = 'Getting class weights'\n",
    "        print(feedback+'\\n'+'-'*len(feedback))\n",
    "        \n",
    "    # validate non falsy inputs\n",
    "    for var in {'targets': targets, 'data': data}:\n",
    "        # if empty or null\n",
    "        if not var:\n",
    "            raise TypeError(f'''Expected non empty input for {var} but received \"falsy\" type {type(var)}''')\n",
    "    \n",
    "    # if received dataframe cast it to dict and continue\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        # ignore the columns we won't use\n",
    "        data = data[targets].to_dict(orient = 'index')\n",
    "    \n",
    "    # workflow for data dictionary\n",
    "    if isinstance(data, dict):\n",
    "        # initialize storage dict\n",
    "        target_class_weights = {}\n",
    "        \n",
    "        # get length of data\n",
    "        data_length = len(data)\n",
    "        if verbose:\n",
    "            print(datetime.now(), \"Available Data Records:\", f\"{data_length:.2E} = {data_length:,}\\n\")\n",
    "        target_class_weights['total_count'] = data_length\n",
    "        \n",
    "        for target_col in targets:\n",
    "            if verbose:\n",
    "                print(datetime.now(), 'weighing classes in target:', target_col)\n",
    "            # initialize a dict for each target column \n",
    "            target_class_weights[target_col] = {}\n",
    "            \n",
    "            # iterate once through the records to get each classes keys\n",
    "            for record in data:\n",
    "                # get the class label at that record\n",
    "                class_label = data[record][target_col]\n",
    "                \n",
    "                # if first time seeing this class, initialize its own dict\n",
    "                if class_label not in target_class_weights[target_col]:\n",
    "                    # initialize its set of records (to avoid the need for iteration searches downstream)\n",
    "                    target_class_weights[target_col][class_label] = {'records':set()}\n",
    "                \n",
    "                # update this class' set of records\n",
    "                target_class_weights[target_col][class_label]['records'].add(record)\n",
    "            \n",
    "            # now that we have each class's set of records, save its count and weight for convenience\n",
    "            for class_label in target_class_weights[target_col]:\n",
    "                target_class_weights[target_col][class_label]['natural_count'] = len(target_class_weights[target_col][class_label]['records'])\n",
    "                target_class_weights[target_col][class_label]['natural_weight'] = target_class_weights[target_col][class_label]['natural_count']/target_class_weights['total_count']\n",
    "                if verbose:\n",
    "                    print(f\"class:{class_label}\")\n",
    "                    for attribute in ['natural_count', 'natural_weight']:\n",
    "                        print(f\"- {attribute}: {target_class_weights[target_col][class_label][attribute]}\")\n",
    "            if verbose:\n",
    "                print('')\n",
    "    # if neither data frame nor dict\n",
    "    else:\n",
    "        raise TypeError(f'Expected data to be type dict or pd.DataFrame but instead got type: {type(data)}')\n",
    "    \n",
    "    return target_class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting data sample of given weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_sampl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare \"Script\" Variables (i.e. input parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load data**\n",
    "\n",
    "Use titanic data set for its mix of numeric and categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data as a dictionary, because they are more efficient when large and of konwn structure than dataframes are\n",
    "data = pd.read_csv('data/semi_processed_all.csv').to_dict(orient = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**declare target columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['EMBARKED_Q', 'EMBARKED_S', 'EMBARKED_C', 'EMBARKED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "\n",
    "# declare sample sizes as percentages of total data size\n",
    "sample_size_percents = [.10, .20, .40, .80, 1.00]\n",
    "# validate sample pcts\n",
    "for pct in sample_sizes:\n",
    "    if pct <=0 or pct > 1:\n",
    "        raise ValueError(f\"Expected percentage between (0, 1] but received {pct}\")\n",
    "\n",
    "# declare weight configurations to use\n",
    "use_natural_weights = True\n",
    "use_balanced_weights = True\n",
    "class_weight_configs = [\n",
    "    {True:.20, False:.80},\n",
    "    {True:.30, False:.70}\n",
    "]\n",
    "# Validation for each class_weight configuration\n",
    "for weighting in class_weight_configs:\n",
    "    # spot check that they add up to 1 (for 100%)\n",
    "    if not np.round(pd.Series(weighting).sum(), 2) == 1:\n",
    "        raise ValueError(f'Invalid or incomplete class weight values. Expected sum to about 1 but got {pd.Series(weighting)}')\n",
    "\n",
    "# if testing/debuging on a single target\n",
    "one_run = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-05 01:07:19.845068 WORKING ON TARGET COLUMN: EMBARKED_Q\n",
      "===================================================\n",
      "Getting class weights\n",
      "---------------------\n",
      "2020-04-05 01:07:19.845326 Available Data Records: 1.31E+03 = 1,309\n",
      "\n",
      "2020-04-05 01:07:19.845400 weighing classes in target: EMBARKED_Q\n",
      "class:False\n",
      "- natural_count: 1186\n",
      "- natural_weight: 0.906035141329259\n",
      "class:True\n",
      "- natural_count: 123\n",
      "- natural_weight: 0.09396485867074103\n",
      "\n",
      "get 0.1 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "get 0.1 percent sample with weights: {True: 0.2, False: 0.8}\n",
      "get 0.1 percent sample with weights: {True: 0.3, False: 0.7}\n",
      "get 0.1 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "get 0.2 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "get 0.2 percent sample with weights: {True: 0.2, False: 0.8}\n",
      "get 0.2 percent sample with weights: {True: 0.3, False: 0.7}\n",
      "get 0.2 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "get 0.4 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "get 0.4 percent sample with weights: {True: 0.2, False: 0.8}\n",
      "get 0.4 percent sample with weights: {True: 0.3, False: 0.7}\n",
      "get 0.4 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "get 0.8 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "get 0.8 percent sample with weights: {True: 0.2, False: 0.8}\n",
      "get 0.8 percent sample with weights: {True: 0.3, False: 0.7}\n",
      "get 0.8 percent sample with weights: {False: 0.5, True: 0.5}\n",
      "get 1.0 percent sample with weights: {False: 0.906035141329259, True: 0.09396485867074103}\n",
      "get 1.0 percent sample with weights: {True: 0.2, False: 0.8}\n",
      "get 1.0 percent sample with weights: {True: 0.3, False: 0.7}\n",
      "get 1.0 percent sample with weights: {False: 0.5, True: 0.5}\n"
     ]
    }
   ],
   "source": [
    "# for each target column in a single data frame\n",
    "for target in target_columns:\n",
    "    if verbose:\n",
    "        print(datetime.now(), 'WORKING ON TARGET COLUMN:', target)\n",
    "        print('===================================================')\n",
    "    \n",
    "    # get target classes, counts, weights, ad recordkeys\n",
    "    class_counts_weights_keys = get_target_class_count_weight_and_recordkeys(targets=[target], data = data)[target]\n",
    "    \n",
    "    if use_natural_weights:\n",
    "        # make this the first item in the list\n",
    "        class_weight_configs = [{class_label:class_counts_weights_keys[class_label]['natural_weight'] for class_label in class_counts_weights_keys}] + class_weight_configs\n",
    "    # get balanced class weights\n",
    "    if use_balanced_weights:\n",
    "        # make this the last item in the list\n",
    "        class_weight_configs += [{clss:np.round(1/len(class_weight_configs[0]),2) for clss in class_weight_configs[0]}]\n",
    "    \n",
    "    # GET DATA SAMPLE\n",
    "    for sample_pct in sample_size_percents:\n",
    "        for use_weights in class_weight_configs:\n",
    "            print('get', sample_pct, 'percent sample with weights:', use_weights)\n",
    "    \n",
    "\n",
    "    # if testing/debuging on a single target\n",
    "    if one_run:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{False: 0.906035141329259, True: 0.09396485867074103},\n",
       " {True: 0.2, False: 0.8},\n",
       " {True: 0.3, False: 0.7},\n",
       " {False: 0.5, True: 0.5}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: 0.906035141329259, True: 0.09396485867074103}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = get_target_class_count_weight_and_recordkeys(\n",
    "    targets = ['EMBARKED_Q'], data=data, verbose = False\n",
    ")['EMBARKED_Q']\n",
    "\n",
    "{class_label:class_dict[class_label]['natural_weight'] for class_label in class_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: {'records': {0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   45,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178,\n",
       "   179,\n",
       "   180,\n",
       "   181,\n",
       "   182,\n",
       "   183,\n",
       "   184,\n",
       "   185,\n",
       "   187,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   192,\n",
       "   193,\n",
       "   194,\n",
       "   195,\n",
       "   197,\n",
       "   199,\n",
       "   200,\n",
       "   201,\n",
       "   202,\n",
       "   203,\n",
       "   204,\n",
       "   205,\n",
       "   206,\n",
       "   207,\n",
       "   209,\n",
       "   210,\n",
       "   211,\n",
       "   212,\n",
       "   213,\n",
       "   215,\n",
       "   216,\n",
       "   217,\n",
       "   218,\n",
       "   219,\n",
       "   220,\n",
       "   221,\n",
       "   222,\n",
       "   223,\n",
       "   224,\n",
       "   225,\n",
       "   226,\n",
       "   227,\n",
       "   228,\n",
       "   229,\n",
       "   230,\n",
       "   231,\n",
       "   232,\n",
       "   233,\n",
       "   234,\n",
       "   235,\n",
       "   236,\n",
       "   237,\n",
       "   238,\n",
       "   239,\n",
       "   240,\n",
       "   242,\n",
       "   243,\n",
       "   244,\n",
       "   246,\n",
       "   247,\n",
       "   248,\n",
       "   249,\n",
       "   250,\n",
       "   251,\n",
       "   252,\n",
       "   253,\n",
       "   254,\n",
       "   255,\n",
       "   256,\n",
       "   257,\n",
       "   258,\n",
       "   259,\n",
       "   261,\n",
       "   262,\n",
       "   263,\n",
       "   265,\n",
       "   266,\n",
       "   267,\n",
       "   268,\n",
       "   269,\n",
       "   270,\n",
       "   271,\n",
       "   272,\n",
       "   273,\n",
       "   275,\n",
       "   276,\n",
       "   277,\n",
       "   279,\n",
       "   281,\n",
       "   282,\n",
       "   283,\n",
       "   284,\n",
       "   285,\n",
       "   286,\n",
       "   287,\n",
       "   288,\n",
       "   290,\n",
       "   291,\n",
       "   292,\n",
       "   293,\n",
       "   294,\n",
       "   295,\n",
       "   296,\n",
       "   297,\n",
       "   298,\n",
       "   299,\n",
       "   302,\n",
       "   304,\n",
       "   305,\n",
       "   306,\n",
       "   307,\n",
       "   308,\n",
       "   309,\n",
       "   310,\n",
       "   311,\n",
       "   312,\n",
       "   313,\n",
       "   314,\n",
       "   315,\n",
       "   316,\n",
       "   317,\n",
       "   318,\n",
       "   319,\n",
       "   320,\n",
       "   321,\n",
       "   323,\n",
       "   324,\n",
       "   325,\n",
       "   326,\n",
       "   327,\n",
       "   328,\n",
       "   329,\n",
       "   331,\n",
       "   332,\n",
       "   333,\n",
       "   334,\n",
       "   335,\n",
       "   336,\n",
       "   337,\n",
       "   338,\n",
       "   339,\n",
       "   340,\n",
       "   341,\n",
       "   342,\n",
       "   343,\n",
       "   344,\n",
       "   345,\n",
       "   346,\n",
       "   347,\n",
       "   348,\n",
       "   349,\n",
       "   350,\n",
       "   351,\n",
       "   352,\n",
       "   353,\n",
       "   354,\n",
       "   355,\n",
       "   356,\n",
       "   357,\n",
       "   360,\n",
       "   361,\n",
       "   362,\n",
       "   363,\n",
       "   365,\n",
       "   366,\n",
       "   367,\n",
       "   369,\n",
       "   370,\n",
       "   371,\n",
       "   372,\n",
       "   373,\n",
       "   374,\n",
       "   375,\n",
       "   376,\n",
       "   377,\n",
       "   378,\n",
       "   379,\n",
       "   380,\n",
       "   381,\n",
       "   382,\n",
       "   383,\n",
       "   384,\n",
       "   385,\n",
       "   386,\n",
       "   387,\n",
       "   389,\n",
       "   390,\n",
       "   391,\n",
       "   392,\n",
       "   393,\n",
       "   394,\n",
       "   395,\n",
       "   396,\n",
       "   397,\n",
       "   398,\n",
       "   399,\n",
       "   400,\n",
       "   401,\n",
       "   402,\n",
       "   403,\n",
       "   404,\n",
       "   405,\n",
       "   406,\n",
       "   407,\n",
       "   408,\n",
       "   409,\n",
       "   410,\n",
       "   413,\n",
       "   414,\n",
       "   415,\n",
       "   416,\n",
       "   417,\n",
       "   418,\n",
       "   419,\n",
       "   420,\n",
       "   422,\n",
       "   423,\n",
       "   424,\n",
       "   425,\n",
       "   426,\n",
       "   427,\n",
       "   429,\n",
       "   430,\n",
       "   431,\n",
       "   432,\n",
       "   433,\n",
       "   434,\n",
       "   435,\n",
       "   436,\n",
       "   437,\n",
       "   438,\n",
       "   439,\n",
       "   440,\n",
       "   441,\n",
       "   442,\n",
       "   443,\n",
       "   444,\n",
       "   445,\n",
       "   446,\n",
       "   447,\n",
       "   448,\n",
       "   449,\n",
       "   450,\n",
       "   451,\n",
       "   452,\n",
       "   453,\n",
       "   454,\n",
       "   455,\n",
       "   456,\n",
       "   457,\n",
       "   458,\n",
       "   460,\n",
       "   461,\n",
       "   462,\n",
       "   463,\n",
       "   464,\n",
       "   465,\n",
       "   466,\n",
       "   467,\n",
       "   469,\n",
       "   470,\n",
       "   471,\n",
       "   472,\n",
       "   473,\n",
       "   474,\n",
       "   475,\n",
       "   476,\n",
       "   477,\n",
       "   478,\n",
       "   479,\n",
       "   480,\n",
       "   481,\n",
       "   482,\n",
       "   483,\n",
       "   484,\n",
       "   485,\n",
       "   486,\n",
       "   487,\n",
       "   488,\n",
       "   489,\n",
       "   490,\n",
       "   491,\n",
       "   492,\n",
       "   493,\n",
       "   494,\n",
       "   495,\n",
       "   496,\n",
       "   497,\n",
       "   498,\n",
       "   499,\n",
       "   500,\n",
       "   503,\n",
       "   504,\n",
       "   505,\n",
       "   506,\n",
       "   507,\n",
       "   508,\n",
       "   509,\n",
       "   511,\n",
       "   512,\n",
       "   513,\n",
       "   514,\n",
       "   515,\n",
       "   516,\n",
       "   518,\n",
       "   519,\n",
       "   520,\n",
       "   521,\n",
       "   522,\n",
       "   523,\n",
       "   524,\n",
       "   526,\n",
       "   527,\n",
       "   528,\n",
       "   529,\n",
       "   530,\n",
       "   531,\n",
       "   532,\n",
       "   533,\n",
       "   534,\n",
       "   535,\n",
       "   536,\n",
       "   537,\n",
       "   538,\n",
       "   539,\n",
       "   540,\n",
       "   541,\n",
       "   542,\n",
       "   543,\n",
       "   544,\n",
       "   545,\n",
       "   546,\n",
       "   547,\n",
       "   548,\n",
       "   549,\n",
       "   550,\n",
       "   551,\n",
       "   553,\n",
       "   554,\n",
       "   555,\n",
       "   556,\n",
       "   557,\n",
       "   558,\n",
       "   559,\n",
       "   561,\n",
       "   562,\n",
       "   563,\n",
       "   564,\n",
       "   565,\n",
       "   566,\n",
       "   567,\n",
       "   568,\n",
       "   569,\n",
       "   570,\n",
       "   571,\n",
       "   572,\n",
       "   574,\n",
       "   575,\n",
       "   576,\n",
       "   577,\n",
       "   578,\n",
       "   579,\n",
       "   580,\n",
       "   581,\n",
       "   582,\n",
       "   583,\n",
       "   584,\n",
       "   585,\n",
       "   586,\n",
       "   587,\n",
       "   588,\n",
       "   589,\n",
       "   590,\n",
       "   591,\n",
       "   592,\n",
       "   594,\n",
       "   595,\n",
       "   596,\n",
       "   597,\n",
       "   598,\n",
       "   599,\n",
       "   600,\n",
       "   601,\n",
       "   602,\n",
       "   603,\n",
       "   604,\n",
       "   605,\n",
       "   606,\n",
       "   607,\n",
       "   608,\n",
       "   609,\n",
       "   610,\n",
       "   611,\n",
       "   614,\n",
       "   615,\n",
       "   616,\n",
       "   617,\n",
       "   618,\n",
       "   619,\n",
       "   620,\n",
       "   621,\n",
       "   622,\n",
       "   623,\n",
       "   624,\n",
       "   625,\n",
       "   627,\n",
       "   628,\n",
       "   630,\n",
       "   631,\n",
       "   632,\n",
       "   633,\n",
       "   634,\n",
       "   635,\n",
       "   636,\n",
       "   637,\n",
       "   638,\n",
       "   639,\n",
       "   640,\n",
       "   641,\n",
       "   642,\n",
       "   643,\n",
       "   644,\n",
       "   645,\n",
       "   646,\n",
       "   647,\n",
       "   648,\n",
       "   649,\n",
       "   650,\n",
       "   651,\n",
       "   652,\n",
       "   655,\n",
       "   656,\n",
       "   658,\n",
       "   659,\n",
       "   660,\n",
       "   661,\n",
       "   662,\n",
       "   663,\n",
       "   664,\n",
       "   665,\n",
       "   666,\n",
       "   667,\n",
       "   668,\n",
       "   669,\n",
       "   670,\n",
       "   671,\n",
       "   672,\n",
       "   673,\n",
       "   674,\n",
       "   675,\n",
       "   676,\n",
       "   677,\n",
       "   678,\n",
       "   679,\n",
       "   681,\n",
       "   682,\n",
       "   683,\n",
       "   684,\n",
       "   685,\n",
       "   686,\n",
       "   687,\n",
       "   688,\n",
       "   689,\n",
       "   690,\n",
       "   691,\n",
       "   692,\n",
       "   693,\n",
       "   694,\n",
       "   695,\n",
       "   696,\n",
       "   698,\n",
       "   699,\n",
       "   700,\n",
       "   701,\n",
       "   702,\n",
       "   704,\n",
       "   705,\n",
       "   706,\n",
       "   707,\n",
       "   708,\n",
       "   709,\n",
       "   710,\n",
       "   711,\n",
       "   712,\n",
       "   713,\n",
       "   714,\n",
       "   715,\n",
       "   716,\n",
       "   717,\n",
       "   719,\n",
       "   720,\n",
       "   721,\n",
       "   722,\n",
       "   723,\n",
       "   724,\n",
       "   725,\n",
       "   726,\n",
       "   728,\n",
       "   729,\n",
       "   730,\n",
       "   731,\n",
       "   732,\n",
       "   733,\n",
       "   734,\n",
       "   735,\n",
       "   736,\n",
       "   737,\n",
       "   738,\n",
       "   739,\n",
       "   740,\n",
       "   741,\n",
       "   742,\n",
       "   743,\n",
       "   744,\n",
       "   745,\n",
       "   746,\n",
       "   747,\n",
       "   748,\n",
       "   750,\n",
       "   751,\n",
       "   752,\n",
       "   753,\n",
       "   754,\n",
       "   755,\n",
       "   756,\n",
       "   757,\n",
       "   758,\n",
       "   759,\n",
       "   760,\n",
       "   761,\n",
       "   762,\n",
       "   763,\n",
       "   764,\n",
       "   765,\n",
       "   766,\n",
       "   769,\n",
       "   770,\n",
       "   771,\n",
       "   772,\n",
       "   773,\n",
       "   774,\n",
       "   775,\n",
       "   777,\n",
       "   779,\n",
       "   780,\n",
       "   781,\n",
       "   782,\n",
       "   783,\n",
       "   784,\n",
       "   785,\n",
       "   786,\n",
       "   788,\n",
       "   789,\n",
       "   791,\n",
       "   792,\n",
       "   793,\n",
       "   794,\n",
       "   795,\n",
       "   796,\n",
       "   797,\n",
       "   798,\n",
       "   799,\n",
       "   800,\n",
       "   801,\n",
       "   802,\n",
       "   803,\n",
       "   804,\n",
       "   805,\n",
       "   806,\n",
       "   807,\n",
       "   808,\n",
       "   809,\n",
       "   810,\n",
       "   811,\n",
       "   812,\n",
       "   813,\n",
       "   814,\n",
       "   815,\n",
       "   816,\n",
       "   817,\n",
       "   818,\n",
       "   819,\n",
       "   820,\n",
       "   821,\n",
       "   822,\n",
       "   823,\n",
       "   824,\n",
       "   826,\n",
       "   827,\n",
       "   829,\n",
       "   830,\n",
       "   831,\n",
       "   832,\n",
       "   833,\n",
       "   834,\n",
       "   835,\n",
       "   836,\n",
       "   837,\n",
       "   838,\n",
       "   839,\n",
       "   840,\n",
       "   841,\n",
       "   842,\n",
       "   843,\n",
       "   844,\n",
       "   845,\n",
       "   846,\n",
       "   847,\n",
       "   848,\n",
       "   849,\n",
       "   850,\n",
       "   851,\n",
       "   852,\n",
       "   853,\n",
       "   854,\n",
       "   855,\n",
       "   856,\n",
       "   857,\n",
       "   858,\n",
       "   859,\n",
       "   860,\n",
       "   861,\n",
       "   862,\n",
       "   863,\n",
       "   864,\n",
       "   865,\n",
       "   866,\n",
       "   867,\n",
       "   868,\n",
       "   869,\n",
       "   870,\n",
       "   871,\n",
       "   872,\n",
       "   873,\n",
       "   874,\n",
       "   875,\n",
       "   876,\n",
       "   877,\n",
       "   878,\n",
       "   879,\n",
       "   880,\n",
       "   881,\n",
       "   882,\n",
       "   883,\n",
       "   884,\n",
       "   886,\n",
       "   887,\n",
       "   888,\n",
       "   889,\n",
       "   892,\n",
       "   894,\n",
       "   895,\n",
       "   896,\n",
       "   898,\n",
       "   899,\n",
       "   900,\n",
       "   901,\n",
       "   902,\n",
       "   903,\n",
       "   904,\n",
       "   905,\n",
       "   906,\n",
       "   908,\n",
       "   909,\n",
       "   910,\n",
       "   911,\n",
       "   912,\n",
       "   913,\n",
       "   914,\n",
       "   915,\n",
       "   916,\n",
       "   917,\n",
       "   918,\n",
       "   919,\n",
       "   920,\n",
       "   921,\n",
       "   922,\n",
       "   923,\n",
       "   924,\n",
       "   925,\n",
       "   926,\n",
       "   927,\n",
       "   928,\n",
       "   929,\n",
       "   930,\n",
       "   931,\n",
       "   932,\n",
       "   933,\n",
       "   934,\n",
       "   935,\n",
       "   936,\n",
       "   937,\n",
       "   939,\n",
       "   940,\n",
       "   941,\n",
       "   942,\n",
       "   943,\n",
       "   944,\n",
       "   945,\n",
       "   947,\n",
       "   948,\n",
       "   949,\n",
       "   950,\n",
       "   951,\n",
       "   952,\n",
       "   953,\n",
       "   955,\n",
       "   956,\n",
       "   958,\n",
       "   959,\n",
       "   960,\n",
       "   962,\n",
       "   963,\n",
       "   964,\n",
       "   965,\n",
       "   966,\n",
       "   967,\n",
       "   968,\n",
       "   969,\n",
       "   971,\n",
       "   972,\n",
       "   973,\n",
       "   974,\n",
       "   976,\n",
       "   978,\n",
       "   980,\n",
       "   981,\n",
       "   982,\n",
       "   983,\n",
       "   984,\n",
       "   985,\n",
       "   986,\n",
       "   987,\n",
       "   988,\n",
       "   989,\n",
       "   990,\n",
       "   991,\n",
       "   992,\n",
       "   994,\n",
       "   995,\n",
       "   996,\n",
       "   999,\n",
       "   1000,\n",
       "   1001,\n",
       "   1003,\n",
       "   1005,\n",
       "   1006,\n",
       "   1007,\n",
       "   1008,\n",
       "   1009,\n",
       "   1010,\n",
       "   1011,\n",
       "   1013,\n",
       "   1014,\n",
       "   1016,\n",
       "   1017,\n",
       "   1019,\n",
       "   1020,\n",
       "   1021,\n",
       "   1022,\n",
       "   1023,\n",
       "   1024,\n",
       "   1025,\n",
       "   1026,\n",
       "   1027,\n",
       "   1028,\n",
       "   1029,\n",
       "   1030,\n",
       "   1031,\n",
       "   1032,\n",
       "   1033,\n",
       "   1034,\n",
       "   1035,\n",
       "   1036,\n",
       "   1037,\n",
       "   1038,\n",
       "   1039,\n",
       "   1040,\n",
       "   1041,\n",
       "   1042,\n",
       "   1043,\n",
       "   1044,\n",
       "   1045,\n",
       "   1046,\n",
       "   1047,\n",
       "   1048,\n",
       "   1049,\n",
       "   1050,\n",
       "   1052,\n",
       "   1053,\n",
       "   1054,\n",
       "   1055,\n",
       "   1056,\n",
       "   1057,\n",
       "   1058,\n",
       "   1059,\n",
       "   1060,\n",
       "   1061,\n",
       "   1062,\n",
       "   1063,\n",
       "   1064,\n",
       "   1065,\n",
       "   1066,\n",
       "   1067,\n",
       "   1068,\n",
       "   1069,\n",
       "   1070,\n",
       "   1071,\n",
       "   1072,\n",
       "   1073,\n",
       "   1075,\n",
       "   1076,\n",
       "   1077,\n",
       "   1078,\n",
       "   1079,\n",
       "   1080,\n",
       "   1081,\n",
       "   1082,\n",
       "   1083,\n",
       "   1085,\n",
       "   1086,\n",
       "   1087,\n",
       "   1088,\n",
       "   1089,\n",
       "   1090,\n",
       "   1092,\n",
       "   1093,\n",
       "   1094,\n",
       "   1095,\n",
       "   1096,\n",
       "   1098,\n",
       "   1099,\n",
       "   1100,\n",
       "   1101,\n",
       "   1102,\n",
       "   ...},\n",
       "  'natural_count': 1186,\n",
       "  'natural_weight': 0.906035141329259},\n",
       " True: {'records': {5,\n",
       "   16,\n",
       "   22,\n",
       "   28,\n",
       "   32,\n",
       "   44,\n",
       "   46,\n",
       "   47,\n",
       "   82,\n",
       "   109,\n",
       "   116,\n",
       "   126,\n",
       "   143,\n",
       "   156,\n",
       "   171,\n",
       "   186,\n",
       "   188,\n",
       "   196,\n",
       "   198,\n",
       "   208,\n",
       "   214,\n",
       "   241,\n",
       "   245,\n",
       "   260,\n",
       "   264,\n",
       "   274,\n",
       "   278,\n",
       "   280,\n",
       "   289,\n",
       "   300,\n",
       "   301,\n",
       "   303,\n",
       "   322,\n",
       "   330,\n",
       "   358,\n",
       "   359,\n",
       "   364,\n",
       "   368,\n",
       "   388,\n",
       "   411,\n",
       "   412,\n",
       "   421,\n",
       "   428,\n",
       "   459,\n",
       "   468,\n",
       "   501,\n",
       "   502,\n",
       "   510,\n",
       "   517,\n",
       "   525,\n",
       "   552,\n",
       "   560,\n",
       "   573,\n",
       "   593,\n",
       "   612,\n",
       "   613,\n",
       "   626,\n",
       "   629,\n",
       "   653,\n",
       "   654,\n",
       "   657,\n",
       "   680,\n",
       "   697,\n",
       "   703,\n",
       "   718,\n",
       "   727,\n",
       "   749,\n",
       "   767,\n",
       "   768,\n",
       "   776,\n",
       "   778,\n",
       "   787,\n",
       "   790,\n",
       "   825,\n",
       "   828,\n",
       "   885,\n",
       "   890,\n",
       "   891,\n",
       "   893,\n",
       "   897,\n",
       "   907,\n",
       "   938,\n",
       "   946,\n",
       "   954,\n",
       "   957,\n",
       "   961,\n",
       "   970,\n",
       "   975,\n",
       "   977,\n",
       "   979,\n",
       "   993,\n",
       "   997,\n",
       "   998,\n",
       "   1002,\n",
       "   1004,\n",
       "   1012,\n",
       "   1015,\n",
       "   1018,\n",
       "   1051,\n",
       "   1074,\n",
       "   1084,\n",
       "   1091,\n",
       "   1097,\n",
       "   1107,\n",
       "   1118,\n",
       "   1124,\n",
       "   1147,\n",
       "   1162,\n",
       "   1164,\n",
       "   1173,\n",
       "   1182,\n",
       "   1195,\n",
       "   1204,\n",
       "   1206,\n",
       "   1249,\n",
       "   1271,\n",
       "   1272,\n",
       "   1279,\n",
       "   1287,\n",
       "   1290,\n",
       "   1299,\n",
       "   1301,\n",
       "   1302},\n",
       "  'natural_count': 123,\n",
       "  'natural_weight': 0.09396485867074103}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_target_class_count_weight_and_recordkeys(\n",
    "    targets = ['EMBARKED_Q'], data=data, verbose = False\n",
    ")['EMBARKED_Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
